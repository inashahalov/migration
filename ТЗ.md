

**ТЕХНИЧЕСКОЕ ЗАДАНИЕ**  
**На выполнение работ по миграции данных и метаданных между экземплярами СУБД PostgreSQL с применением шифрования по ГОСТ при помощи Apache Spark**

**1. Общие положения**  
Настоящее техническое задание (далее — ТЗ) определяет требования к выполнению разовой миграции структурных объектов базы данных и табличных данных из источника (PostgreSQL) в целевую базу данных (PostgreSQL). Миграция осуществляется с использованием Apache Spark в качестве ETL-движка с обязательным шифрованием указанных полей по алгоритмам ГОСТ при помощи программного обеспечения CryptoPro JCP.

**2. Цель работ**  
Обеспечить полный и согласованный перенос следующих объектов из исходной базы данных в целевую:
- пользовательских схем (за исключением системных схем `pg_catalog`, `information_schema`);
- таблиц и их данных;
- материализованных и нематериализованных представлений (вьюх);
- последовательностей, индексов и ограничений целостности (первичные, уникальные, внешние ключи, проверочные ограничения).

Данные, содержащие персональную или иную конфиденциальную информацию, подлежат шифрованию в процессе обработки в Spark в соответствии с требованиями безопасности.

**3. Требования к содержанию миграции**

3.1. **Метаданные**  
Структура целевой базы данных должна быть полностью воссоздана до начала загрузки данных. Для этого необходимо:
- выполнить выгрузку DDL-скриптов из источника с исключением операторов, относящихся к управлению доступом (`GRANT`, `REVOKE`, `CREATE ROLE`, `ALTER ROLE` и аналогичных);
- применить полученные DDL-скрипты к целевой базе данных.

3.2. **Данные**  
Данные должны быть перенесены в полном объёме. Порядок загрузки таблиц должен учитывать зависимости по внешним ключам. При необходимости допускается временное отключение ограничений внешних ключей на время загрузки с последующим их включением и проверкой целостности.

3.3. **Шифрование**  
Следующие поля подлежат шифрованию по алгоритмам ГОСТ (ГОСТ 28147-89 или ГОСТ Р 34.10-2012 — по согласованию):
- ФИО;
- серия и номер паспорта;
- ИНН / СНИЛС;
- адрес электронной почты и иные персональные идентификаторы, определённые Заказчиком.

Шифрование реализуется в рамках Spark-приложения с использованием Java Security Provider от CryptoPro (JCP). Ключи шифрования не должны храниться в исходном коде и должны передаваться через безопасные механизмы (файлы, переменные окружения, защищённые vault-системы).

**4. Требования к реализации**

4.1. **Технологический стек**  
- Язык реализации: Scala (предпочтительно) или Python (PySpark).
- СУБД: PostgreSQL 12+ (оба экземпляра).
- ETL-движок: Apache Spark 3.x.
- Криптография: CryptoPro JCP, версия не ниже 2.0.
- Протокол подключения: JDBC.

4.2. **Архитектура процесса**
1. Выгрузка и применение DDL к целевой базе данных.
2. Последовательная обработка таблиц:
   - чтение данных из источника по JDBC с возможностью партиционирования (при наличии числового первичного ключа);
   - применение пользовательских функций (UDF) для шифрования указанных колонок;
   - запись результата в целевую базу данных по JDBC.
3. Постобработка:
   - обновление материализованных представлений (`REFRESH MATERIALIZED VIEW`);
   - обновление статистики (`ANALYZE`);
   - валидация объёмов данных.

4.3. **Надёжность и сопровождение**
- Приложение должно логировать ключевые этапы выполнения, включая начало/окончание обработки каждой таблицы, количество обработанных записей, ошибки.
- В случае сбоя обработка должна быть остановлена с формированием отчёта об ошибке. Возможность частичного перезапуска не обязательна, но желательна.
- Конфигурационные параметры (строки подключения, пути к ключам, список шифруемых полей) должны быть вынесены в отдельный файл конфигурации.







