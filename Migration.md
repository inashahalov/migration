
# **Техническое задание**  
## Миграция данных из монолитной системы в микросервисную архитектуру  
### Финтех-контекст  

---

### 1. Цель проекта  
Обеспечить безопасную, идемпотентную и поэтапную миграцию структурированных данных из монолитной базы данных (PostgreSQL) в целевые базы данных микросервисов (в том числе MS SQL), минимизируя риски потери данных, нарушения целостности и простоя бизнес-процессов.

---

### 2. Контекст  
- **Источник**: монолитное приложение с единой реляционной СУБД (PostgreSQL).  
- **Цель**: микросервисы с архитектурой «одна БД на сервис» (database-per-service), включая MS SQL и, при необходимости, ClickHouse для аналитических нагрузок.  
- **Отрасль**: финтех → повышенные требования к целостности данных, воспроизводимости и аудиту.  
- **Тип миграции**: поддержка как однократной (one-time), так и инкрементальной (batch/streaming) синхронизации.

---

### 3. Ключевые принципы  
- **Постепенность**: использование паттерна *Strangler Fig* — миграция по частям без полного отключения системы.  
- **Приоритизация**: сначала загружаются справочники (dimensions), затем — таблицы фактов (facts).  
- **Идемпотентность**: повторный запуск любого этапа не приводит к дублированию или повреждению данных.  
- **Наблюдаемость**: сквозное логирование, метрики объёмов и скорости, валидация контрольных сумм.  
- **Обратимость**: возможность отката или восстановления исходного состояния без потери информации.

---

### 4. Этапы реализации  

#### 4.1. Анализ и подготовка  
- Получение доступов к БД-источнику и целевым БД.  
- Аудит структуры: таблицы, столбцы, типы данных, ограничения (PK/FK/Check), индексы.  
- Оценка объёмов данных (количество строк, размер на диске).  
- Построение графа зависимостей между таблицами → определение топологического порядка загрузки.

#### 4.2. Проектирование целевой схемы  
- Генерация DDL для целевой СУБД (MS SQL) с адаптацией типов:  
  - `SERIAL` → `IDENTITY`,  
  - `TIMESTAMP` → `DATETIME2`,  
  - учёт различий в collation и nullability.  
- Ручная переработка программных объектов: функции, триггеры, хранимые процедуры (PL/pgSQL → T-SQL).  
- Уточнение стратегии идентификаторов (UUID vs. автоинкремент).

#### 4.3. Оркестрация и выполнение  
- Реализация пайплайна на **Apache Airflow**:  
  - DAG с зависимостями, соответствующими порядку «справочники → факты».  
  - Поддержка режимов: полная миграция и инкрементальная синхронизация.  
- Копирование данных:  
  - Пакетами (например, по 100 000 строк).  
  - Сначала во временную таблицу → валидация → перенос в постоянную.  
- Обеспечение идемпотентности: проверка существования объектов перед созданием, отслеживание watermark’ов.

#### 4.4. Валидация и наблюдаемость  
- Сравнение:  
  - Количества строк (row count),  
  - Контрольных сумм (например, hash по составному ключу).  
- Логирование в централизованную систему (Elasticsearch / Loki).  
- Визуализация в Grafana / Kibana: объёмы, скорость, ошибки.  
- Настройка алертов при отклонениях (> 0,1%).

#### 4.5. Пост-миграционная поддержка  
- Удаление временных таблиц.  
- Создание индексов после завершения загрузки (для производительности).  
- Документирование:  
  - Скрипты миграции,  
  - Сопоставление схем,  
  - Перечень ручных доработок (логика на стороне БД).

---

### 5. Риски и меры снижения  

| Риск | Мера снижения |
|------|----------------|
| Несовместимость типов данных | Ранний аудит + тестовая миграция на подмножестве данных |
| Нарушение ссылочной целостности | Загрузка в порядке зависимостей (справочники → факты) |
| Потеря данных при инкременте | Использование watermark’ов; в будущем — CDC (Debezium) |
| Таймауты из-за больших объёмов | Батчинг + retry-логика в Airflow |
| Ошибки в T-SQL-логике | Code review и unit-тестирование процедур/представлений |

---

### 6. Критерии успеха  
- Все целевые таблицы созданы и корректно заполнены.  
- Целостность данных подтверждена автоматической валидацией.  
- Миграция выполнена без остановки бизнес-процессов.  
- Пайплайн полностью документирован и воспроизводим.  
- Заложена основа для будущих инкрементальных синхронизаций.

---

### 7. Технологический стек  
- **Источник**: PostgreSQL  
- **Цель**: MS SQL, при необходимости — ClickHouse  
- **Оркестрация**: Apache Airflow  
- **Мониторинг и логирование**: Grafana, Loki, Elasticsearch, Kibana  
- **Языки**: SQL (PL/pgSQL, T-SQL), Python (для Airflow и валидации)

---


